{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5cc3a05-6a5f-4d2f-a2c1-cef095e74824",
   "metadata": {},
   "source": [
    "# Implementing and using iterable datasets: What Could Go Wrong?\n",
    "\n",
    "\n",
    "**Goal**: Understand different issues *users* have to deal with when they use **iterable** datasets. *Users* = us, as domain libs authors; and also our downstream users.\n",
    "\n",
    "**Why is this relevant to us?**  Because datapipes are planned to be first-class citizens of the PyTorch data loading ecosystem. Datapipes **are** iterable datasets so everything we'll discuss is relevant for datapipes as well.\n",
    "\n",
    "**Disclaimer**: this talk might be confusing. It's actually the point (kinda).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8149cc9-8a81-4707-a731-95fdce554f20",
   "metadata": {},
   "source": [
    "## Let's start with the basics\n",
    "\n",
    "#### Map-style datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a62715-0c6a-4e21-a2c8-201620fcc9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "class MyMapStyleDS:\n",
    "    \n",
    "    def __init__(self, size=100):\n",
    "        self.size = size\n",
    "        \n",
    "    def __getitem__(self, i):  # Returns the i'th sample\n",
    "        # Here: read from disk [+ decoding] [+ transforms]\n",
    "        s = i\n",
    "        return s\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    \n",
    "mapstyle_ds = MyMapStyleDS()\n",
    "mapstyle_dl = data.DataLoader(mapstyle_ds, batch_size=10)\n",
    "\n",
    "for batch in mapstyle_dl:\n",
    "    print(batch)\n",
    "    # Here: forward and backward passes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3f0b5-a652-4717-86d1-e48d05303026",
   "metadata": {},
   "source": [
    "#### Iterable datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0046826-0e29-43da-b03e-f1a13e8df510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "class MyIterableDS(data.IterableDataset):\n",
    "    \n",
    "    def __init__(self, size=100):\n",
    "        self.size = size\n",
    "        \n",
    "    def __iter__(self):  # iterate over samples\n",
    "        # Here: read from disk [+ decoding] [+ transforms]\n",
    "        for s in range(self.size):\n",
    "            yield s\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    \n",
    "iter_ds = MyIterableDS()\n",
    "iter_dl = data.DataLoader(iter_ds, batch_size=10)\n",
    "\n",
    "for batch in iter_dl:\n",
    "    print(batch)\n",
    "    # Here: forward and backward passes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a4c2e3-433d-44a7-a788-1715fb59e3cc",
   "metadata": {},
   "source": [
    "### So far so good\n",
    "## Let's add some parallelism <o/\n",
    "\n",
    "We'll cover:\n",
    "\n",
    "- DataLoader parallelism\n",
    "- DDP parallelism\n",
    "\n",
    "Fun fact: they're not mutually exclusive\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3725d1f-7253-4f8a-96de-a3cc75bb01bf",
   "metadata": {},
   "source": [
    "### DataLoader parallelism\n",
    "\n",
    "#### Map-style - EZPZ lemon squeezy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f268c08-5f42-4f93-9612-e17f6c58520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "mapstyle_dl = data.DataLoader(mapstyle_ds, batch_size=10, num_workers=4)\n",
    "\n",
    "for batch in mapstyle_dl:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190df695-40d0-4391-90ae-40002b85cb9a",
   "metadata": {},
   "source": [
    "#### Iterable - ~EZPZ lemon squeezy~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac29b80-cc17-494f-88c7-1d50c1abab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "iter_dl = data.DataLoader(iter_ds, batch_size=10, num_workers=5)\n",
    "\n",
    "for batch in iter_dl:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f21f8f-9dea-488c-8257-89271936115b",
   "metadata": {},
   "source": [
    "### Oops. What went wrong?\n",
    "\n",
    "\n",
    "Let's dive into the DataLoader internals.\n",
    "\n",
    "<img src=\"imgs/DL.jpg\" width=\"500\"/>\n",
    "\n",
    "What we have: all workers see the same data\n",
    "\n",
    "<img src=\"imgs/dataset_basic.svg\" width=\"300\"/>\n",
    "\n",
    "\n",
    "What we want: some sharding\n",
    "\n",
    "<img src=\"imgs/dataset_sharded.svg\" width=\"300\"/>\n",
    "\n",
    "\n",
    "\n",
    "- **Map-style dataset**: main DataLoader process is able to request specific indices from each worker\n",
    "- **Iterable dataset**: there's no notion of \"indices\". All the DataLoader can do is to request the \"next\" sampler from each worker, via `None`.\n",
    "  - So we need to tell each worker which samples belong to them.\n",
    "  - We have to do that **manually**.\n",
    "  - There's no standard or cannonical way.\n",
    "  \n",
    " \n",
    "TL;DR: it's hard 🥲\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36611ae0-34c2-4802-a1a7-b74eb3f6d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  4,  8, 12, 16, 20, 24, 28, 32, 36])\n",
      "tensor([ 1,  5,  9, 13, 17, 21, 25, 29, 33, 37])\n",
      "tensor([ 2,  6, 10, 14, 18, 22, 26, 30, 34, 38])\n",
      "tensor([ 3,  7, 11, 15, 19, 23, 27, 31, 35, 39])\n",
      "tensor([40, 44, 48, 52, 56, 60, 64, 68, 72, 76])\n",
      "tensor([41, 45, 49, 53, 57, 61, 65, 69, 73, 77])\n",
      "tensor([42, 46, 50, 54, 58, 62, 66, 70, 74, 78])\n",
      "tensor([43, 47, 51, 55, 59, 63, 67, 71, 75, 79])\n",
      "tensor([80, 84, 88, 92, 96])\n",
      "tensor([81, 85, 89, 93, 97])\n",
      "tensor([82, 86, 90, 94, 98])\n",
      "tensor([83, 87, 91, 95, 99])\n"
     ]
    }
   ],
   "source": [
    "class MyIterableDS(data.IterableDataset):\n",
    "    \n",
    "    def __init__(self, size=100):\n",
    "        self.size = size\n",
    "        \n",
    "    def __iter__(self):  # iterate over samples\n",
    "        worker_info = data.get_worker_info()\n",
    "        num_workers = worker_info.num_workers\n",
    "        worker_id = worker_info.id\n",
    "        \n",
    "        for i, s in enumerate(range(self.size)):\n",
    "            if i % num_workers == worker_id:\n",
    "                yield s\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    \n",
    "iter_ds = MyIterableDS()\n",
    "iter_dl = data.DataLoader(iter_ds, batch_size=10, num_workers=4)\n",
    "\n",
    "for batch in iter_dl:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae47a3-c386-48c2-9a32-d9e14ea425eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Works OK, but:\n",
    "\n",
    "- Manual and boilerplate code, and there's no standard\n",
    "- Notice the difference with Map-style Dataset (not a big deal tho)\n",
    "- **Notice the batch size at the end!!**. This can have [bad consequences](https://github.com/pytorch/data/issues/302) when batch-norm is involved. Solution: use `drop_last=True`; but ideally we shouldn't need to.\n",
    "\n",
    "#### Now let's take a look at DDP parallelism\n",
    "\n",
    "What is DDP (Distributed Data Parallel)?\n",
    "- N copies of the model, typically on N GPUs (== N DDP processes).\n",
    "- The N models see different parts of the data  <-- **That's the important part**\n",
    "- The N models' weights are kept equal via gradient synchronization\n",
    "\n",
    "\n",
    "<img src=\"https://www.telesens.co/wp-content/uploads/2017/12/img_5a416615431e7.png\" width=\"500\"/>\n",
    "\n",
    "(Image source: https://www.telesens.co/2017/12/25/understanding-data-parallelism-in-machine-learning/)\n",
    "\n",
    "\n",
    "Let's look at this outside of this notebook (if we have time): see [this file](https://github.com/NicolasHug/iterable_ds_pres/blob/main/issues_with_ddp.py)\n",
    "\n",
    "\\<insert pain here\\>\n",
    "\n",
    "TL;DR:\n",
    "\n",
    "- The exact same sharding issue happens (but for other reasons)\n",
    "- So we need to shard across **DDP workers** (just like we sharded across DataLoader workers above)\n",
    "- DataLoader multi-processing can be embedded within a DDP multi-process:\n",
    "  - **So we need 2 levels of sharding**: DDP *and* DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4bc436b-c149-4b5e-a44e-b8935162d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIterableDS(data.IterableDataset):\n",
    "    \n",
    "    def __init__(self, size=100):\n",
    "        self.size = size\n",
    "        \n",
    "    def __iter__(self):  # iterate over samples\n",
    "        \n",
    "        worker_info = data.get_worker_info()\n",
    "        num_dl_workers = worker_info.num_workers\n",
    "        dl_worker_id = worker_info.id\n",
    "\n",
    "        num_ddp_workers = dist.get_world_size()\n",
    "        ddp_worker_id = dist.get_rank()\n",
    "        \n",
    "        for i, s in enumerate(range(self.size)):  # We need 2 levels of sharding!!\n",
    "            if i % num_ddp_workers == ddp_worker_id:\n",
    "                if i % num_dl_workers == dl_worker_id:\n",
    "                    yield s\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3f977-c362-4a69-96e8-b8266f982f0d",
   "metadata": {},
   "source": [
    "But IRL you'll need a lot of glue code (e.g. only shard when DDP is on).\n",
    "And with datapipes, these 2 sharding filters can happen at different stages of the pipeline, which complicates things.\n",
    "\n",
    "## More fun: shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e78c35-2300-47e2-aeed-1524dfcdc812",
   "metadata": {},
   "source": [
    "#### Map-style: EZPZ lemon squeezy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59adea2e-f534-4ff0-b650-10dd8ba08a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([95, 94, 74, 63,  4, 86, 55, 58, 50, 39])\n",
      "tensor([76, 51, 48, 52,  0, 67, 20, 57, 23, 10])\n",
      "tensor([18, 71, 17, 24, 93, 45, 33,  3, 81, 87])\n",
      "tensor([ 1, 27, 46, 15, 91, 47, 54, 85, 66, 49])\n",
      "tensor([64, 88, 68, 56, 59, 12, 69, 14, 83, 75])\n",
      "tensor([98, 34, 78, 99, 77, 32,  7, 13,  9, 97])\n",
      "tensor([70,  8, 30, 36, 41, 90, 16, 73, 65, 92])\n",
      "tensor([42, 79, 53, 29, 35, 26, 40, 61, 19,  5])\n",
      "tensor([89, 31, 44, 21, 80, 82, 11,  2, 43, 37])\n",
      "tensor([28, 84, 22, 96, 60,  6, 25, 62, 38, 72])\n"
     ]
    }
   ],
   "source": [
    "sampler = data.RandomSampler(mapstyle_ds)\n",
    "mapstyle_dl = data.DataLoader(mapstyle_ds, batch_size=10, num_workers=4, sampler=sampler)\n",
    "\n",
    "for batch in mapstyle_dl:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0160985-14d6-4f10-8c09-5149be154929",
   "metadata": {},
   "source": [
    "#### Iterable: ~EZPZ lemon squeezy~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab4bfc8-2fe5-4741-b841-bc99292a515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = data.RandomSampler(iter_ds)\n",
    "iter_ds = MyIterableDS()\n",
    "# Samplers aren't allows, this raises an error:\n",
    "# iter_dl = data.DataLoader(iter_ds, batch_size=10, num_workers=4, sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d38589-d91c-4b0b-b294-574e240595d8",
   "metadata": {},
   "source": [
    "#### OK, let's shuffle manually then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d75617-35c9-46c3-a221-4315360c4e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 12, 72, 36, 80,  4,  0, 28, 92, 84])\n",
      "tensor([73, 53, 65, 21, 85, 17, 45, 57, 29,  5])\n",
      "tensor([26, 66, 90, 14, 10, 54, 82, 74, 62, 22])\n",
      "tensor([43, 39, 79, 51, 87, 83, 19, 59, 47, 63])\n",
      "tensor([40,  8, 96, 60, 16, 52, 48, 56, 76, 32])\n",
      "tensor([97, 41, 89, 61, 33, 81, 77, 49, 25, 37])\n",
      "tensor([ 6, 78, 50,  2, 34, 70, 38, 98, 58, 42])\n",
      "tensor([67, 31, 75,  7, 99, 95, 23, 55,  3, 27])\n",
      "tensor([68, 64, 44, 88, 24])\n",
      "tensor([ 1,  9, 13, 69, 93])\n",
      "tensor([30, 86, 46, 94, 18])\n",
      "tensor([91, 15, 71, 11, 35])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class MyIterableDS(data.IterableDataset):\n",
    "    \n",
    "    def __init__(self, size=100):\n",
    "        self.size = size\n",
    "        \n",
    "    def __iter__(self):  # iterate over samples\n",
    "        worker_info = data.get_worker_info()\n",
    "        num_workers = worker_info.num_workers\n",
    "        worker_id = worker_info.id\n",
    "        \n",
    "        buffer = []\n",
    "        \n",
    "        for i, s in enumerate(range(self.size)):\n",
    "            if i % num_workers == worker_id:\n",
    "                buffer.append(s)\n",
    "        \n",
    "        random.shuffle(buffer)\n",
    "        \n",
    "        yield from buffer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "iter_ds = MyIterableDS()\n",
    "iter_dl = data.DataLoader(iter_ds, batch_size=10, num_workers=4)\n",
    "\n",
    "for batch in iter_dl:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53efd5f-0940-4987-8115-3aaaf37b6380",
   "metadata": {},
   "source": [
    "#### Looks random 🤩\n",
    "\n",
    "Narrator: *It's not*\n",
    "\n",
    "And it's **not obvious** to diagnose. Each individual worker is only shuffling **within its own shard** (the green bits).\n",
    "\n",
    "<img src=\"imgs/dataset_sharded.svg\" width=\"300\"/>\n",
    "\n",
    "That's not uniform shuffling: the same samples are always being batched together. It can have dramatic effects on the accuracy, especially when the underlying files are stored in a per-class folder structure.\n",
    "\n",
    "**We need to shuffle before we shard**. So let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d3ca0c2-6659-4efc-b72b-6936ab88fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([82, 93, 84,  6, 94, 51, 96, 48, 14, 66])\n",
      "tensor([74, 87, 75, 27, 92, 50, 96, 45, 39, 35])\n",
      "tensor([69, 32,  8, 85,  0, 96, 27, 71, 94, 91])\n",
      "tensor([92, 28, 32, 90, 80, 79,  2, 77, 48, 60])\n",
      "tensor([80,  8, 36, 85, 77, 79,  1, 53, 27, 41])\n",
      "tensor([68, 71, 82,  5,  3,  4, 51, 79, 84, 41])\n",
      "tensor([43, 14,  9,  1, 92, 82, 77, 76, 67, 30])\n",
      "tensor([15, 51, 97, 20, 66, 54, 57, 74, 24, 21])\n",
      "tensor([29, 16,  5, 44, 63])\n",
      "tensor([55, 48, 69, 46,  2])\n",
      "tensor([19, 26, 53, 23, 68])\n",
      "tensor([78, 40, 98,  6, 75])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "\n",
    "class MyIterableDS(data.IterableDataset):\n",
    "    \n",
    "    def __init__(self, size=100):\n",
    "        self.size = size\n",
    "        \n",
    "    def __iter__(self):  # iterate over samples\n",
    "        worker_info = data.get_worker_info()\n",
    "        num_workers = worker_info.num_workers\n",
    "        worker_id = worker_info.id\n",
    "        \n",
    "        buffer = []\n",
    "        for s in range(self.size):\n",
    "            buffer.append(s)\n",
    "                \n",
    "        random.shuffle(buffer)\n",
    "        \n",
    "        for i, s in enumerate(buffer):\n",
    "            if i % num_workers == worker_id:\n",
    "                yield s\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "iter_ds = MyIterableDS()\n",
    "iter_dl = data.DataLoader(iter_ds, batch_size=10, num_workers=4)\n",
    "\n",
    "batches = []\n",
    "for batch in iter_dl:\n",
    "    print(batch)\n",
    "    batches.append(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c251d-7a09-499c-bb6d-4184b435acb4",
   "metadata": {},
   "source": [
    "#### Did it work now? 🤩\n",
    "\n",
    "\n",
    "Narrator: *it didn't*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "654348e1-f941-4b3e-a962-ae7a721b01ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1,\n",
       "         1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2,\n",
       "         1, 3, 1, 3, 2, 3, 2, 2, 1, 1, 1, 3, 1, 2, 3, 1, 1]),\n",
       " torch.Size([65]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples = torch.cat(batches)\n",
    "_, counts = torch.unique(all_samples, return_counts=True)\n",
    "counts, counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174cc72-bc98-446e-a631-26bf8902ae56",
   "metadata": {},
   "source": [
    "**Reason**: all workers use a [different RNG seed](https://github.com/pytorch/pytorch/blob/3ac27e78ca5429b47a63826a1bb678031d20bffd/torch/utils/data/_utils/worker.py#L217-L223) for shuffling, so some samples can be missing or duplicated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75083c9-9a73-4593-9f90-10b645119757",
   "metadata": {},
   "source": [
    "#### So we need the same RNG seed across workers 🤓. Phew!!\n",
    "\n",
    "Narrator: *still no*.\n",
    "\n",
    "We don't want that either: we still want the RNG of the sample transformations (done within the workers) to be different.\n",
    "\n",
    "We **only** want the seed for **shuffling** to be the same across workers (meaning: across DataLoader workers **and** DDP workers).\n",
    "\n",
    "Idea: pass the shuffling seed in `__init__()`. But **be careful**: we still need to make sure the seed will be different across epochs (remember [`DistributedSampler.set_epoch()`](https://github.com/pytorch/pytorch/blob/401179f263d5ba22731de107874f41fdd256737f/torch/utils/data/distributed.py#L100)?)\n",
    "\n",
    "TL;DR: it's hard 🥲\n",
    "\n",
    "*The implementation of an iterable dataset that properly handles DDP and DataLoader multiprocessing, shuffling and sharding, all within a simple user-friendly API that does not expose low-level implementation details, is left as an exercise to the reader.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf3540e-644b-4998-94f2-d9ba00f8f634",
   "metadata": {},
   "source": [
    "## Take away:\n",
    "\n",
    "We've seen a bunch of issues with iterable datasets:\n",
    "  - Related to sharding / multiprocessing\n",
    "    - inside the DataLoader\n",
    "    - outside the DataLoader (DDP)\n",
    "    - when both are involved\n",
    "  - Related to shuffling\n",
    "  - Related to the *order* of these operation: shuffling before sharding\n",
    "\n",
    "Hopefully, you're confused. It is confusing! **We cannot expect our users to understand all this**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf02a2c7-f5af-4610-bc93-ee455b14dd3e",
   "metadata": {},
   "source": [
    "### We need **cannonical, high-level, robust APIs** that will prevent users from falling into all these traps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7111f79-e4ae-4e66-9d58-61e159c799d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
